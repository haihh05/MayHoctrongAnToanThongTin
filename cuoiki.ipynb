{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeLOGDLx9HOt",
        "outputId": "96a9e519-efa0-4d8a-f5f6-74982e4d376b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1zPuZu9i8Im4WMZ5cFL912zEeSxPj-zX3\n",
            "From (redirected): https://drive.google.com/uc?id=1zPuZu9i8Im4WMZ5cFL912zEeSxPj-zX3&confirm=t&uuid=de6fe784-3b33-47e0-84cf-6b31950d7f32\n",
            "To: /content/train.csv\n",
            "100% 601M/601M [00:07<00:00, 82.9MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1xbVwPQqZdiVvYt33tKu4AM2QWi4W3VQ8\n",
            "From (redirected): https://drive.google.com/uc?id=1xbVwPQqZdiVvYt33tKu4AM2QWi4W3VQ8&confirm=t&uuid=d51487fd-2cdd-4c72-ba33-180e647bf934\n",
            "To: /content/test.csv\n",
            "100% 246M/246M [00:02<00:00, 122MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1zPuZu9i8Im4WMZ5cFL912zEeSxPj-zX3\n",
        "!gdown 1xbVwPQqZdiVvYt33tKu4AM2QWi4W3VQ8"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, when\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler, MinMaxScaler\n",
        "from pyspark.ml import Pipeline\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from pyspark.ml.classification import GBTClassifier\n",
        "from xgboost.spark import SparkXGBClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
      ],
      "metadata": {
        "id": "WjtGr4FV-MjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Spark session\n",
        "spark = SparkSession.builder.appName(\"DataProcessingAndModeling\").getOrCreate()"
      ],
      "metadata": {
        "id": "0TRUemKsnZfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"train.csv\"\n",
        "df = spark.read.csv(data_path, header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "rCgk4HFs-lsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data processing\n",
        "\n",
        "1. Filling nan value of each column with median value\n",
        "\n",
        "2. Encoding any categorical features columns\n",
        "\n",
        "3. Building features column and remove Identify column include \"ID\", \"Label\", \"Protocal type\"\n",
        "4. Normalize features with MinMax Scaler"
      ],
      "metadata": {
        "id": "CEwYHrRZBf1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Preprocessing\n",
        "# Handle missing values (e.g., fill nulls with median or mean)\n",
        "for col_name in df.columns:\n",
        "    if df.select(col_name).dtypes[0][1] == \"double\" or df.select(col_name).dtypes[0][1] == \"int\":\n",
        "        median_value = df.stat.approxQuantile(col_name, [0.5], 0.1)[0]\n",
        "        df = df.fillna({col_name: median_value})\n",
        "    else:\n",
        "        df = df.fillna({col_name: \"unknown\"})"
      ],
      "metadata": {
        "id": "-5TtZzrhCnQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Label encoding for categorical features (if any)\n",
        "label_indexer = StringIndexer(inputCol=\"Label\", outputCol=\"LabelIndex\")\n",
        "protocol_indexer = StringIndexer(inputCol=\"Protocol type\", outputCol=\"ProtocolIndex\")"
      ],
      "metadata": {
        "id": "WNv0NfY5nnas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assemble features into a single vector\n",
        "feature_columns = [col for col in df.columns if col not in [\"ID\", \"Label\", \"Protocol type\"]]\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")"
      ],
      "metadata": {
        "id": "4WzMBjBxBebx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize features\n",
        "scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")"
      ],
      "metadata": {
        "id": "0mpd3WcACiJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a pipeline for transformations\n",
        "pipeline = Pipeline(stages=[label_indexer, protocol_indexer, assembler, scaler])\n",
        "model = pipeline.fit(df)\n",
        "processed_df = model.transform(df)"
      ],
      "metadata": {
        "id": "bOSeyEutnw9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split training set into training set and validation set\n",
        "\n",
        "#### The ratio is 70% training and 30% validation"
      ],
      "metadata": {
        "id": "NURCxTDZ5n8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split_train_df, split_test_df = processed_df.randomSplit(weights=[0.7,0.3], seed=100)"
      ],
      "metadata": {
        "id": "cdVon42H5vwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gbt_split = SparkXGBClassifier(label_col=\"LabelIndex\", features_col=\"scaledFeatures\", maxIter=1, maxDepth=5, num_cpus=4)\n",
        "gbt_model_split = gbt_split.fit(split_train_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzbeBdep5zx_",
        "outputId": "9db0e82c-9bb1-4f9a-ada5-acf783f485db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'objective': 'multi:softprob', 'device': 'cpu', 'maxIter': 1, 'maxDepth': 5, 'num_cpus': 4, 'num_class': 34, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_split = gbt_model_split.transform(split_test_df)"
      ],
      "metadata": {
        "id": "n1NaoHj3_69d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"LabelIndex\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(y_pred_split)\n",
        "print(f\"Test Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSGTSLCcAGyJ",
        "outputId": "aaa0e60e-bb04-4279-f72a-8271e5fd9f75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9358977209560867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training all model with training set"
      ],
      "metadata": {
        "id": "wAgUhOkB5iKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gbt = SparkXGBClassifier(label_col=\"LabelIndex\", features_col=\"scaledFeatures\", maxIter=100, maxDepth=5)\n",
        "gbt_model = gbt.fit(processed_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssRRgGupn27s",
        "outputId": "31574359-de9c-4597-d7f8-e711f8f9cf59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'objective': 'multi:softprob', 'device': 'cpu', 'maxIter': 100, 'maxDepth': 5, 'num_class': 34, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gbt_model.save(\"xgboost\")"
      ],
      "metadata": {
        "id": "j_Lbtib923X1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r xgboost.zip xgboost"
      ],
      "metadata": {
        "id": "GKF-Hisq3wh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate testing set"
      ],
      "metadata": {
        "id": "8quOpB5W5l3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load test data\n",
        "test_path = 'test.csv'\n",
        "test_df = spark.read.csv(test_path, header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "sZ8TDKupqYol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle missing values in test data (same logic as training data)\n",
        "for col_name in test_df.columns:\n",
        "    if test_df.select(col_name).dtypes[0][1] == \"double\" or test_df.select(col_name).dtypes[0][1] == \"int\":\n",
        "        median_value = df.stat.approxQuantile(col_name, [0.5], 0.1)[0]\n",
        "        test_df = test_df.fillna({col_name: median_value})\n",
        "    else:\n",
        "        test_df = test_df.fillna({col_name: \"unknown\"})"
      ],
      "metadata": {
        "id": "_2l-4dCNqdx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the trained pipeline to test data\n",
        "processed_test_df = model.transform(test_df)"
      ],
      "metadata": {
        "id": "e_DaXbfFqe8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "y_pred = gbt_model.transform(processed_test_df)"
      ],
      "metadata": {
        "id": "yY5dc0Imqi0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "id": "IthR1N7J17-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Evaluate the model\n",
        "# evaluator = MulticlassClassificationEvaluator(labelCol=\"LabelIndex\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "# accuracy = evaluator.evaluate(y_pred)\n",
        "# print(f\"Test Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "iyuhB7eRqj3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nu6tXj_WyKEc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}